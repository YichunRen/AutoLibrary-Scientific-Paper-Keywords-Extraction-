{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Replication - Result Analysis\n",
    "\n",
    "Let's explore more about the AutoPhrase's results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import re\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Try to randomly pick 100 multi-word phrases whose scores are greater than 0.5. Manually check them and see what's the percentage of high-quality phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../references/annotated_multi-words.csv\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_quality = sample[sample['label'] == 1].reset_index(drop=True)\n",
    "p = high_quality.shape[0] / sample.shape[0] * 100\n",
    "\n",
    "print('The percentage of high-quality phrases is: ' + str(p) + '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Since these 100 multi-word phrases can be ranked by their scores, please plot a precision-recall curve too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_true=sample['label'],\n",
    "    probas_pred=sample['score']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, scalex=False, scaley=False)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for 100 Multi-Word Phrases')\n",
    "\n",
    "#plt.savefig('../data/report/Precision-Recall Curve for 100 Multi-Word Phrases.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try to run the word2vec code on the phrasal segmentation results to obtain phrase embedding. \n",
    "\n",
    "To convert the phrasal segmentation results, we replace empty spaces inside phrase tags by underscores. \n",
    "\n",
    "- For example, if the line looks like: \n",
    "    - `<phrase>Overview</phrase> of the ADDS System. <phrase>Transaction Management</phrase> in <phrase>Multidatabase Systems</phrase>.`\n",
    "- The converted line should look like:\n",
    "    - `Overview of the ADDS System. Transaction_Management in Multidatabase_Systems.`\n",
    "    \n",
    "Then we train the Word2Vec model on the phrasal segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = pd.read_csv('../data/out/AutoPhrase_multi-words.txt', sep=\"\t\", header=None)\n",
    "multi.columns = ['score', 'phrase']\n",
    "multi = multi[multi.score > 0.5].reset_index(drop=True)\n",
    "multi = multi['phrase'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"../data/report/word2vec.model\")\n",
    "exist = []\n",
    "for phrase in high_quality['phrase'].to_list():\n",
    "    phrase = phrase.replace(' ', '_')\n",
    "    if phrase in model.wv:\n",
    "        exist.append(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pick 3 high-quality phrases from your previous annotations in step 1, run a similarity search among all multi-word phrases whose scores are greater than 0.5, and report the top-5 results. Comment on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = dict()\n",
    "#for p1 in ['hearing_aid', 'design_studio', 'waste_water_treatment']:\n",
    "for p1 in exist:\n",
    "    sim = model.wv.most_similar(positive=p1)\n",
    "    lst = []\n",
    "    count = 0\n",
    "    for pair in sim:\n",
    "        if count > 4:\n",
    "            continue\n",
    "        else:\n",
    "            p2 = pair[0].replace('_', ' ')\n",
    "            if p2 in multi:\n",
    "                lst.append(pair[0])\n",
    "                count += 1\n",
    "    if len(lst) == 5 and len(similar) < 3:\n",
    "        similar[p1] = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_5 = pd.DataFrame.from_dict(similar)\n",
    "#sim_5.to_csv('../data/report/Top 5 Similar Multi-Word Phrases.csv')\n",
    "sim_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each group of phrases show syntactic and semantic similarities in different ways, but this shows that AutoPhrase can successfully extract phrases that we can use to group together into different categories from the same corpus.\n",
    "\n",
    "Note: Since Word2Vec models perform poorly on small data, there would be no similar phrases for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
