0.9176500000	information extraction
0.9155500000	knowledge base
0.8598071429	domain specific
0.8504333333	raw frequency
0.8396000000	text corpora
0.8374452381	quality single word phrases
0.8279833333	phrase mining
0.8212200593	cn
0.8170897575	auc
0.8060166667	dw ½
0.8055500000	rectified frequency
0.8024559867	ieee
0.8023285714	high quality phrases
0.8015000000	phrase quality
0.8008656015	shang
0.7991049997	illinois
0.7988785714	word sequence
0.7978783308	wikipedia
0.7942238095	wikipedia article datasets
0.7931943437	art
0.7893024948	chinese
0.7850115882	proc
0.7762785714	pos tagger
0.7729333333	keyphrase extraction
0.7676023810	single word phrases
0.7674737100	data
0.7620452381	positive pool
0.7563452381	negative labels
0.7553678063	en
0.7545333333	auc curves
0.7529833333	massive text corpora
0.7526952381	quality phrases
0.7509621773	fig
0.7480955410	human
0.7410928940	þ
0.7401509969	business
0.7376452381	multiple languages
0.7362603880	database
0.7354307092	pos
0.7337619048	quality score
0.7331846580	information
0.7329561669	algorithm
0.7311701581	np
0.7303389354	english
0.7276825664	natural
0.7218456283	viterbi
0.7187809612	performance
0.7178904762	general knowledge
0.7166437312	research
0.7137471223	mining
0.7137471223	knowledge
0.7127149950	linguistics
0.7125071429	phrase candidates
0.7115166667	natural language
0.7104762754	linguistic
0.7097109960	training
0.7082113303	dpen
0.7057134202	section
0.7036857143	single word phrase
0.7035848173	labels
0.7023221341	size
0.7010409195	paper
0.7004369838	extraction
0.6996523810	precision recall curves
0.6992666667	wikipedia article
0.6989243929	autophrase
0.6974814886	noun
0.6970308059	dblp
0.6967071429	pos tag
0.6941049906	high
0.6940052172	idf
0.6909071429	 þ
0.6872690476	pre trained
0.6869860331	corpora
0.6865725927	segmentation
0.6862523810	single word
0.6835580250	probability
0.6829606896	domain
0.6811370948	corpus
0.6804071429	general knowledge bases
0.6789882102	sequence
0.6772305009	positive
0.6762839712	domains
0.6753313310	experts
0.6729659955	engineering
0.6726402166	language
0.6717234523	model
0.6716616099	epen
0.6705452381	domain experts
0.6705425494	based
0.6690325830	tags
0.6648169615	google
0.6630270112	nlp
0.6625054182	phd
0.6614964281	set
0.6609264047	frequency
0.6608119048	quality estimator
0.6600523810	negative pool
0.6573322045	united
0.6554693435	acm
0.6554693435	dpdn
0.6544363955	base
0.6542166667	phrase mining method
0.6502904762	phrasal segmentation
0.6489756985	textrank
0.6470460809	models
0.6429333333	quality phrase
0.6410285714	high quality
0.6389725120	dðtx
0.6376762906	text
0.6370579339	gb
0.6352817919	raw
0.6352728322	es
0.6346119048	precision recall
0.6345591381	quality
0.6345238095	linguistic analyzers
0.6302419367	spanish
0.6302419367	comput
0.6301571429	distant training
0.6297501226	recall
0.6273864338	autosegphrase
0.6272190476	pos tags
0.6245775002	results
0.6243333333	word phrases
0.6221441921	score
0.6218452381	shown in fig
0.6215523810	human effort
0.6212481573	yelp
0.6198357143	½ bi
0.6168333333	pos quality
0.6153130224	languages
0.6148373298	datasets
0.6143213981	trained
0.6133333333	english datasets
0.6131910209	uu
0.6107072156	estimation
0.6094348101	ideal
0.6094348101	rectified
0.6075360886	retrieval
0.6066971653	int
0.6066458907	compared
0.6057804278	percent
0.6053262830	assoc
0.6053262830	wrapsegphrase
0.6053262830	ren
0.6053262830	wang
0.6053262830	note
0.6053262830	champaign
0.6010605599	specific
0.6004816763	han
0.5918240959	analysis
0.5899435939	½
0.5897354691	lang
0.5897354691	liu
0.5896616711	words
0.5886847107	precision
0.5886825468	methods
0.5880660658	candidates
0.5852051854	bi
0.5805547724	complete
0.5803190476	knowledge bases
0.5795355017	proposed
0.5792118478	learn
0.5780773012	conf
0.5764404762	number of words
0.5759960408	award
0.5751904762	army research
0.5743309524	robust positive only distant training
0.5714357143	½ i
0.5693029479	trees
0.5662352695	
0.5655092715	memory
0.5628692610	addition
0.5605634612	segphrase
0.5593838931	phrase
0.5584375699	negative
0.5571768516	single
0.5561288412	form
0.5559583172	statistical
0.5558761905	pos guided phrasal segmentation
0.5538690476	human annotation
0.5501135208	¼
0.5490195067	general
0.5475023810	ieee transactions
0.5457129801	noise
0.5433637248	phrases
0.5400523810	shang et al
0.5376342865	independence
0.5369810982	effort
0.5353071429	evaluated by
0.5324642857	business reviews
0.5312265070	feature
0.5300698792	method
0.5300546470	great
0.5296876103	table
0.5286924912	concepts
0.5280740752	dw
0.5274632709	number
0.5262796214	papers
0.5254952381	different languages
0.5242703912	experiments
0.5233645271	process
0.5230064455	tag
0.5224755968	segment
0.5215713326	automatic
0.5206840160	input
0.5182537203	multiple
0.5162039227	long
0.5162039227	speedup
0.5160185563	defined
0.5145489489	parameters
0.5139132605	informativeness
0.5132626056	
0.5119952381	this paper
0.5068949377	tagger
0.5066996422	pool
0.5065935674	machine
0.5050943675	techniques
0.5050705509	efficiency
0.5043223544	comparison
0.5032337785	case
0.5025568886	word
0.5012071429	based on
0.5006957023	ensemble
0.4985658428	existing
0.4963842368	indexing
0.4961325204	popular
0.4957815678	shown
0.4956084723	decision
0.4951703285	significant
0.4940764692	compare
0.4940764692	study
0.4940764692	index
0.4921463709	interesting
0.4919120511	example
0.4915639105	evaluation
0.4912071429	transactions on knowledge
0.4905191683	dataset
0.4899642857	positive only distant training
0.4891437594	leverage
0.4884857143	university of illinois
0.4879261455	processing
0.4875966976	scores
0.4865112464	degree
0.4865112464	designed
0.4865112464	strong
0.4865112464	received
0.4865112464	independent
0.4865112464	framework
0.4839619048	automated phrase mining
0.4834314505	i.e
0.4822599854	completeness
0.4822599854	concordance
0.4819732004	complex
0.4814051888	e
0.4810049869	dependency
0.4793071958	present
0.4786826209	similar
0.4781587882	generate
0.4781587882	scientific
0.4781587882	criteria
0.4781313514	trends
0.4771447527	evaluated
0.4771447527	keyphrase
0.4769073326	speech
0.4755031172	classifier
0.4755031172	previous
0.4754253147	firewall
0.4733736562	collection
0.4733077586	github.com
0.4733077586	candidate
0.4733077586	classifiers
0.4733077586	support
0.4718419414	modeling
0.4715518051	gap
0.4714943321	works
0.4714943321	labeling
0.4709736169	vol
0.4696210865	accuracy
0.4691193391	context
0.4682704327	expert
0.4682704327	linear
0.4682704327	sense
0.4682704327	introduce
0.4682704327	list
0.4682704327	term
0.4682704327	mentions
0.4682704327	names
0.4682704327	improvements
0.4682704327	expensive
0.4682704327	threshold
0.4682704327	estimate
0.4682704327	shows
0.4682704327	boundary
0.4682704327	topical
0.4667779334	terms
0.4643618780	pre
0.4643618780	robust
0.4638238095	as follows
0.4615880141	articles
0.4615880141	baseline
0.4615880141	biþ1þþ
0.4615880141	times
0.4609105502	
0.4593924020	large
0.4593924020	document
0.4589309490	ranked
0.4589309490	propose
0.4589309490	efficient
0.4589309490	features
0.4589309490	incorporating
0.4589309490	outperforms
0.4589309490	rules
0.4589309490	including
0.4589309490	biþ1þ
0.4589309490	segments
0.4589309490	extract
0.4587806554	pools
0.4587309524	part of speech
0.4583804992	multi
0.4583804992	
0.4563692095	error
0.4558014710	https
0.4557804517	article
0.4552404762	different domains
0.4550905691	topic
0.4547190476	uu and dðtx
0.4535268123	computer
0.4534477236	documents
0.4507307600	length
0.4495009503	curves
0.4489023810	more than
0.4485942220	effectively
0.4477437039	massive
0.4466255484	e.g
0.4461785714	segmentation model
0.4424488005	pp
0.4399843452	phrasal
0.4388987011	tyþ
0.4369809524	as shown in
0.4333446178	
0.4288828532	–
0.4272688354	x
0.4261023810	n grams
0.4216211393	i
0.4148309524	i ¼ 1
0.4067190476	in proc
0.4062809524	as well as
0.4055968658	j
0.4048738095	such as
0.4044584119	than
0.4001404762	university of
0.3946738095	defined as
0.3893809524	a complete semantic unit
0.3882944871	instead
0.3874761905	the size of
0.3850208923	following
0.3846523810	the pos guided phrasal segmentation
0.3819685685	c
0.3813391962	given
0.3811216797	more
0.3800985229	n
0.3776309524	rely on
0.3763095238	october 2018
0.3756309524	refers to
0.3752357143	auc curves of
0.3698238095	from massive text corpora
0.3642026538	such
0.3637925823	g
0.3637925823	y
0.3631837546	to
0.3622707780	different
0.3621571429	the positive pool
0.3619119048	in addition
0.3617857143	compared to
0.3588285714	the u.s
0.3576761905	the department of computer science
0.3553142857	state of
0.3546638388	h
0.3515619048	quality phrases from
0.3514967647	only
0.3502428571	10 to 30 percent
0.3468357143	automated phrase mining from massive text
0.3455047619	e mail
0.3396915739	well
0.3390928571	et al
0.3362976190	on knowledge and data engineering
0.3342523810	the phrasal segmentation
0.3322749526	b
0.3303488468	as
0.3299619048	of autophrase
0.3284238095	for example
0.3275919900	overall
0.3247216395	s
0.3208823941	therefore
0.3178142857	due to
0.3145340440	this
0.3138690476	in different languages
0.3131428992	three
0.3117399659	k
0.3114976190	according to
0.3102579204	30
0.3100285714	a phrase
0.3066190476	the same
0.3058190476	the negative pool
0.3047573677	2018
0.3045095238	computer science
0.3038661012	in
0.3023571429	and cn
0.2981375703	on
0.2932103216	the
0.2874357940	best
0.2871442623	part
0.2861396427	even
0.2817404762	set of
0.2802280463	of
0.2795133721	he
0.2780338394	by
0.2768068277	from
0.2765955044	a
0.2765889487	10
0.2761976190	in different domains
0.2749015564	follows
0.2743785714	the corpus
0.2741071429	phrases from
0.2724619048	phrase mining from
0.2723988513	r
0.2723721843	his
0.2705785714	all methods
0.2701904762	of high quality
0.2646888298	into
0.2622142857	the university of
0.2604018612	automated
0.2585857143	the art
0.2554238095	and negative
0.2551405323	m
0.2551022575	been
0.2542523810	the following
0.2541836468	then
0.2536305359	4
0.2532119048	the phrase
0.2531976190	the number of
0.2531238095	number of
0.2524548896	because
0.2509253146	and
0.2492400407	at
0.2470857143	probability of
0.2470774882	all
0.2466792375	however
0.2466692920	may
0.2443189595	were
0.2442344830	without
0.2441178101	most
0.2435707222	better
0.2419071429	to model
0.2409770236	23
0.2404063161	non
0.2402990125	an
0.2393983316	novel
0.2390833333	the phrase quality
0.2389785232	l
0.2381351852	20
0.2381351852	usually
0.2381351852	9
0.2379368185	these
0.2378136778	about
0.2375077049	almost
0.2365487353	for
0.2361642857	different domains and
0.2357602081	is
0.2350984156	w
0.2350984156	p
0.2332291786	after
0.2330062963	further
0.2312203068	within
0.2301078042	new
0.2295825270	five
0.2290579753	first
0.2277737367	11
0.2277737367	if
0.2277737367	becomes
0.2277737367	enough
0.2270273161	time
0.2264444676	1
0.2252627215	some
0.2239404762	shown in
0.2236518532	t
0.2230661657	there
0.2223404330	d
0.2220902322	over
0.2220181876	using
0.2211547952	available
0.2211547952	one
0.2210534827	8
0.2209446318	15
0.2202840488	2015
0.2202840488	respectively
0.2202840488	especially
0.2202840488	12
0.2202840488	four
0.2202840488	show
0.2202840488	above
0.2202840488	like
0.2202840488	certain
0.2202840488	u
0.2196815704	be
0.2187742342	among
0.2187742342	use
0.2187742342	them
0.2187742342	38
0.2187742342	2010
0.2187742342	their
0.2187742342	do
0.2187742342	2017
0.2184307259	0
0.2184307259	where
0.2184031909	should
0.2184031909	used
0.2178372172	how
0.2178372172	13
0.2178363930	very
0.2169579322	two
0.2164904762	the given
0.2159773098	will
0.2154694349	also
0.2154071429	the best
0.2147452381	in section
0.2145285714	in fig
0.2140296802	both
0.2135018999	any
0.2135018999	7
0.2135018999	5
0.2135018999	many
0.2134742901	our
0.2121248138	it
0.2119832619	while
0.2116972814	when
0.2114192713	other
0.2079338308	we
0.2079135416	they
0.2075791897	between
0.2075791897	or
0.2075791897	@
0.2065452381	the ideal
0.2064111916	has
0.2061073968	work
0.2057487130	no
0.2057312868	each
0.2057312868	6
0.2040344560	not
0.2035269933	its
0.2025134798	but
0.2024608233	3
0.2024608233	2
0.2020134798	have
0.2003785714	a quality
0.1998919467	which
0.1993919467	can
0.1977280971	with
0.1969954436	that
0.1959285714	the results
0.1954102229	are
0.1941571429	instead of
0.1932238095	autophrase and
0.1917952381	the proposed
0.1838238095	phrases in
0.1833119048	¼ 1
0.1830404762	complete in
0.1807785714	and chinese
0.1780452381	the domain
0.1654690476	domains and
0.1637238095	the probability
0.1633571429	of words
0.1572738095	frequency of
0.1516785714	of positive
0.1511785714	the precision
0.1467571429	as well
0.1459071429	and j
0.1438285714	the chinese
0.1430119048	the positive
0.1429785714	of phrases
0.1418619048	a complete
0.1387571429	a more
0.1385619048	the en
0.1366571429	the performance
0.1365119048	the pos
0.1339904762	and c
0.1253404762	by human
0.1133404762	the three
0.1125738095	part of
0.0849738095	the size
0.0753571429	in different
