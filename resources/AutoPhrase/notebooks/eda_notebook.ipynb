{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Purposes:\n",
    "- How many documents/sentences/tokens are there in your input corpus? \n",
    "- What are the length distributions of documents and sentences? Any outliers?\n",
    "- What is the distribution of all tokens? How many \"rare\" tokens (e.g., < 5 times)? \n",
    "- Is there any pre-processing required? e.g., remove the consecutive whitespace, remove some \"weird\" characters.\n",
    "- Run AutoPhrase, and then plot the quality score distribution of single-word and multi-word phrases separately. Compare and discuss their differences.\n",
    "\n",
    "**Note:** \n",
    "- For this project replication, we are asked to use DBLP.txt as input file. The following is the exploratory data analysis of DBLP.txt and the results of AutoPhrasing it. If the input dataset is another one, one can ignore the explainations.\n",
    "- Since out model is DBLP.txt, which has its own ways to distinguish documents. The dataset have to follow the same structure to calculate its corresponding distributions correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from scipy.stats import skew \n",
    "#ignore future warning because of different versions in the environment\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from tqdm import tqdm # Visualization of loop progress\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "# Analyze the distributions and statistics of input corpus \n",
    "## 1. How many documents/sentences/tokens are there in the input corpus? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts of documents/sentences/tokens\n",
    "\n",
    "Note: The results contain duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/eda/eda_files/count_stats.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What are the length distributions of documents and sentences? Any outliers?\n",
    "## Length distribution of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = pd.read_csv('../data/eda/eda_files/all_doc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "doc_length = doc_df['Document_len']\n",
    "sns.distplot(doc_length).set_title('Distribution of Documents Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 5)\n",
    "sns.boxplot(doc_length).set_title('Distribution of Documents Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/eda/eda_files/doc_stats.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: As we can see from the graphs and statistics above,  documents has an extreme right-skew distribution in terms of lengths.  We also investigated the outliers (i.e. more than 1.5 times IQR from 75-percentile) of document length. In total, there are about 23% outliers in total samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length distribution of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.read_csv('../data/eda/eda_files/all_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent_length = [len(sent.split()) for sent in sent_df['Sentence']]\n",
    "sent_length = sent_df['Sentence_len']\n",
    "sns.distplot(sent_length).set_title('Distribution of Sentence Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(sent_length).set_title('Distribution of Sentence Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/eda/eda_files/sent_stats.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see from the graphs and statistics above,  sentences has a right-skew distribution in terms of lengths.  We also investigated the outliers (i.e. more than 1.5 times IQR from 75-percentile) of sentence length. Compared to document length, there are much less outliers. In total, there are about 2.55% outliers in total samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  What is the distribution of all tokens? How many \"rare\" tokens (e.g., < 5 times)?\n",
    "### Frequency distribution of token\n",
    "\n",
    "Note: Instead of length, we care more about the frequency of each unique tokens. The following are the distribution and statistics about the frequency.\n",
    "\n",
    "**Infrequent(rare) token:** Frequence < 5\n",
    "\n",
    "**Frequent token:** Frequency >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token = pd.read_csv('../data/eda/eda_files/all_token_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_token.shape[0] > 1000:\n",
    "    sns.distplot([i for i in all_token['Count'] if i >= 5]).set_title('Frequency Distribution of Frequent Tokens')\n",
    "else:\n",
    "    plt.hist([i for i in all_token['Count']])\n",
    "    plt.title('Frequency Distribution of Tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When it comes to the token frequency, the distribution is even more skewed. Therefore, we only consider the token with more than five appearances, which takes up approximately 15% of the total unique token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/eda/eda_files/token_stats.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of initial cleaning, there is no required preprocessing step. Subtle problems in the input file will be solved when running AutoPhrase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "# Analyze the results of AutoPhrase\n",
    "## 1. Plot the quality score distribution of Multi-word phrases\n",
    "**From the graph, we notice the distribution is right skewed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_word_scores = pd.read_csv('../data/eda/eda_files/multi_score.csv', index_col=0)\n",
    "sns.distplot(multi_word_scores['Scores']).set_title('Distribution of Multi-word Phrases Quality Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot the quality score distribution of Single-word phrases\n",
    "**From the graph, we notice the distribution is symmetric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_scores = pd.read_csv('../data/eda/eda_files/single_score.csv', index_col=0)\n",
    "sns.distplot(single_word_scores['Scores']).set_title('Distribution of Single-word Phrases Quality Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the distributions in the same graph for comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11.7,8.27))\n",
    "sns.distplot(multi_word_scores['Scores'], color=\"skyblue\", kde = False, label = 'Multi Words')\n",
    "sns.distplot(single_word_scores['Scores'], color=\"olive\", kde = False, label = 'Single Word')\n",
    "fig.legend(labels=['Multi Words', 'Single Word'])\n",
    "plt.suptitle('Distributions of Single-word & Multi-word Phrases Quality Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this distribution we have two main observations.\n",
    "The number of high-score single-word phrases is much less than that of multi-word phrases. The main reason is that phrases make the most sense when they are accompanied by other words, in which the “most sense” refers to the quality of the phrases. For example, “data” might be overwhelmingly seen across documents, but it might not be a high quality phrase based on the quality measurement of AutoPhrase framework, because the information it provides is limited and it is not “complete”. However, when it is combined with other words, the information it delivers increases dramatically. For example, “data warehouse” is of more “quality” than just “data” and that has a much higher score of 0.95. \n",
    "The raw number of single-word phrases is also less than that of multi-word phrases. This is due to the fact that, as mentioned in the previous point, the overall quality of the single-word phrases is lower than that of the multi-word counterparts, which makes us drop lots of the single-word phrases during the modelling process in exchange for higher quality phrases.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
