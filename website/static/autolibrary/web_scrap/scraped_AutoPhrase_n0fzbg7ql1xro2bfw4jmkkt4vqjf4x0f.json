[{"link": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9010996", "title": "ShellNet: Efficient Point Cloud Convolutional Neural Networks Using Concentric Shells Statistics", "authors": [{"firstName": "Zhiyuan", "middleNames": [], "lastName": "Zhang"}, {"firstName": "Binh-Son", "middleNames": [], "lastName": "Hua"}, {"firstName": "Sai-Kit", "middleNames": [], "lastName": "Yeung"}], "abstract": "Deep learning with 3D data has progressed significantly since the introduction of convolutional neural networks that can handle point order ambiguity in point cloud data. While being able to achieve good accuracies in various scene understanding tasks, previous methods often have low training speed and complex network architecture. In this paper, we address these problems by proposing an efficient end-to-end permutation invariant convolution for point cloud deep learning. Our simple yet effective convolution operator named ShellConv uses statistics from concentric spherical shells to define representative features and resolve the point order ambiguity, allowing traditional convolution to perform on such features. Based on ShellConv we further build an efficient neural network named ShellNet to directly consume the point clouds with larger receptive fields while maintaining less layers. We demonstrate the efficacy of ShellNet by producing state-of-the-art results on object classification, object part segmentation, and semantic scene segmentation while keeping the network very fast to train.", "date": "2019-08-17"}, {"link": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8953546", "title": "Spherical Fractal Convolutional Neural Networks for Point Cloud Recognition", "authors": [{"firstName": "Yongming", "middleNames": [], "lastName": "Rao"}, {"firstName": "Jiwen", "middleNames": [], "lastName": "Lu"}, {"firstName": "J.", "middleNames": [], "lastName": "Zhou"}], "abstract": "We present a generic, flexible and 3D rotation invariant framework based on spherical symmetry for point cloud recognition. By introducing regular icosahedral lattice and its fractals to approximate and discretize sphere, convolution can be easily implemented to process 3D points. Based on the fractal structure, a hierarchical feature learning framework together with an adaptive sphere projection module is proposed to learn deep feature in an end-to-end manner. Our framework not only inherits the strong representation power and generalization capability from convolutional neural networks for image recognition, but also extends CNN to learn robust feature resistant to rotations and perturbations. The proposed model is effective yet robust. Comprehensive experimental study demonstrates that our approach can achieve competitive performance compared to state-of-the-art techniques on both 3D object classification and part segmentation tasks, meanwhile, outperform other rotation invariant models on rotated 3D object classification and retrieval tasks by a large margin.", "date": "2019-06-01"}, {"link": "https://arxiv.org/pdf/1906.00764.pdf", "title": "Approximation capability of neural networks on spaces of probability measures and tree-structured domains", "authors": [{"firstName": "T.", "middleNames": [], "lastName": "Pevn\u00fd"}, {"firstName": "Vojt\u011bch", "middleNames": [], "lastName": "Kova\u0159\u00edk"}], "abstract": "This paper extends the proof of density of neural networks in the space of continuous (or even measurable) functions on Euclidean spaces to functions on compact sets of probability measures. By doing so the work parallels a more then a decade old results on mean-map embedding of probability measures in reproducing kernel Hilbert spaces. The work has wide practical consequences for multi-instance learning, where it theoretically justifies some recently proposed constructions. The result is then extended to Cartesian products, yielding universal approximation theorem for tree-structured domains, which naturally occur in data-exchange formats like JSON, XML, YAML, AVRO, and ProtoBuffer. This has important practical implications, as it enables to automatically create an architecture of neural networks for processing structured data (AutoML paradigms), as demonstrated by an accompanied library for JSON format.", "date": "2018-09-27"}, {"link": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8885536", "title": "Unsupervised Feature Learning for Point Cloud Understanding by Contrasting and Clustering Using Graph Convolutional Neural Networks", "authors": [{"firstName": "L.", "middleNames": [], "lastName": "Zhang"}, {"firstName": "Z.", "middleNames": [], "lastName": "Zhu"}], "abstract": "To alleviate the cost of collecting and annotating large-scale \"3D object\" point cloud data, we propose an unsupervised learning approach to learn features from an unlabeled point cloud dataset by using part contrasting and object clustering with deep graph convolutional neural networks (GCNNs). In the contrast learning step, all the samples in the 3D object dataset are cut into two parts and put into a \"part\" dataset. Then a contrast learning GCNN (ContrastNet) is trained to verify whether two randomly sampled parts from the part dataset belong to the same object. In the cluster learning step, the trained ContrastNet is applied to all the samples in the original 3D object dataset to extract features, which are used to group the samples into clusters. Then another GCNN for clustering learning (ClusterNet) is trained from the orignal 3D data to predict the cluster IDs of all the training samples. The contrasting learning forces the ContrastNet to learn semantic features of objects, while the ClusterNet improves the quality of learned features by being trained to discover objects that belong to the same semantic categories by using cluster IDs. We have conducted extensive experiments to evaluate the proposed framework on point cloud classification tasks. The proposed unsupervised learning approach obtains comparable performance to the state-of-the-art with heavier shape auto-encoding unsupervised feature extraction methods. We have also tested the networks on object recognition using partial 3D data, by simulating occlusions and perspective views, and obtained practically useful results. The code of this work is publicly available at: https://github.com/lingzhang1/ContrastNet.", "date": "2019-09-01"}, {"link": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8756610", "title": "Facial Action Unit Analysis through 3D Point Cloud Neural Networks", "authors": [{"firstName": "Michael", "middleNames": ["J."], "lastName": "Reale"}, {"firstName": "Benjamin", "middleNames": [], "lastName": "Klinghoffer"}, {"firstName": "Micah", "middleNames": [], "lastName": "Church"}, {"firstName": "Hannah", "middleNames": [], "lastName": "Szmurlo"}, {"firstName": "L.", "middleNames": [], "lastName": "Yin"}], "abstract": "Facial expression analysis on 3D data has the potential to avoid many of the difficulties heir to 2D data, such as lighting variations and non-frontal pose. In particular, analysis of 3D point cloud data (as opposed to depth maps) offers the potential for higher-resolution, pose-invariant features. Because neural networks and deep learning have proven to be very powerful tools for a wide variety of tasks in recent history, one would naturally wish to apply deep learning for expression analysis of 3D point data. However, the overwhelming majority of these methods target 2D image data, and there are only a few works that utilize 3D point data directly in a neural network for any purpose. That said, the results of these works show improvement over using other forms of data. Therefore, in this work, we experiment with recent successful architectures and propose a new architecture, Local Continuous PointNet (LCPN), for unordered 3D point cloud analysis to detect Action Units (AUs) in the BP4D-Spontaneous database. We also perform cross-database experiments on subjects from the BP4D+ database. To the best of the authors\u2019 knowledge, this is the first work that directly processes unordered 3D point clouds in a neural network for facial expression analysis.", "date": "2019-05-01"}]