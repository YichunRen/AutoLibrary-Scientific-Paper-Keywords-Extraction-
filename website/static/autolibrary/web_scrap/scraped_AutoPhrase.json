[{"link": "https://www.ncbi.nlm.nih.gov/pubmed/31622857", "title": "R-Ensembler: A greedy rough set based ensemble attribute selection algorithm with kNN imputation for classification of medical data", "authors": [{"firstName": "R.", "middleNames": ["K."], "lastName": "Bania"}, {"firstName": "Anindya", "middleNames": [], "lastName": "Halder"}], "abstract": "BACKGROUND AND OBJECTIVE\nRetrieving meaningful information from high dimensional dataset is an important and challenging task. Normally, medical dataset suffers from several issues such as curse of dimensionality problem, uncertainty, presence of missing values, non-relevant and redundant attributes, etc. Any machine learning technique applied on such data (without any preprocessing) by and large takes a considerable amount of computational time and may degrade the performance of the model.\n\n\nMETHODS\nIn this article, R-Ensembler, a parameter free greedy ensemble attribute selection method is proposed adopting the concept of rough set theory by using the attribute-class, attribute-significance and attribute-attribute relevance measures to select a subset of attributes which are most relevant, significant and non-redundant from a pool of different attribute subsets in order to predict the presence or absence of different diseases in medical dataset. The main role of the proposed ensembler is to combine multiple subsets of attributes produced by different rough set filters and to produce an optimal subset of attributes for subsequent classification task. A novel n number of set intersection method is also proposed to reduce the biasness during the time of attribute selection process. Before selecting the minimal attribute set from a given data by the proposed R-Ensembler method, the dataset is preprocessed by the k nearest neighbour (kNN) imputation method for missing value treatment.\n\n\nRESULTS\nExperiments are carried out on seven benchmark medical datasets collected from University of California at Irvine (UCI) repository. The performance of the proposed ensemble method is compared with five state-of-the-art attribute selection algorithms, results of which are measured using three benchmark classifiers viz., Na\u00efve Bayes, decision trees and random forest. Experimental results clearly justify the superiority of the proposed R-Ensembler method over other attribute selection algorithms. Results of paired t-test performed on average accuracies produced by different classifiers simulated on the reduced data sets achieved by the proposed and counter part attribute selection methods confirm the statistical significance of the better reduced attribute subsets achieved by the proposed R-Ensembler method compared to others.\n\n\nCONCLUSION\nThe proposed ensemble method turned out to be very effective for selecting high relevant, high significant and less redundant attributes from a pool of different subsets of attributes.", "date": "2020-02-01"}, {"link": "https://doi.org/10.1007/S11277-019-06715-1", "title": "Opportunistic Mobile Data Offloading Using Machine Learning Approach", "authors": [{"firstName": "S.", "middleNames": [], "lastName": "Dash"}, {"firstName": "Jibitesh", "middleNames": [], "lastName": "Mishra"}, {"firstName": "S.", "middleNames": [], "lastName": "Mishra"}], "abstract": "Currently, cellular networks both 3G and 4G are heavily overloaded due to increasing usage of mobile applications. Offloading mobile data traffic through opportunistic communications is one of promising solution to solve this problem. This has huge advantage over other kinds of offloading techniques like no extra cost, significant reduction of mobile traffic, high efficiency. As a case of study, we are focusing our investigation in opportunistic communication for optimizing target set selection problem. A new algorithm is proposed for generating target set which uses machine learning paradigm. Since, machine learning is an emerging sector in computer science with lots of potential; we integrated it with offloading procedure to achieve better performance in real world scenario. The efficiency of proposed method is measured by comparing it with other methods like Greedy, Heuristic and Random. A case study is conducted incorporating this approach and performance evaluation is done. It can be ensured from this comparison that the proposed algorithm outperforms its counterparts.", "date": "2020-01-01"}, {"title": "Towards Offline Arabic Handwritten Character Recognition Based on Unsupervised Machine Learning Methods: A Perspective Study", "authors": [{"firstName": "N.", "middleNames": [], "lastName": "Hasasneh"}, {"firstName": "Ahmad", "middleNames": [], "lastName": "Hasasneh"}, {"firstName": "N.", "middleNames": [], "lastName": "Salman"}, {"firstName": "Derar", "middleNames": [], "lastName": "Eleyan"}], "abstract": "This paper proposes an alternative approach for the problem of Arabic handwritten character recognition. The proposed model is based on Deep Belief Networks (DBNs) which are unsupervised machine learning methods. A greedy layer-wise fashion based on Restricted Boltzmann Machines and contrastive divergence learning algorithm will be used to train such model. Previous studies have shown that DBNs are capable to extract a set of sparse features, which can be used to code the initial data in an efficient way. The assumption is that such representation must improve the linear separation among the different classes and thus a simple classification algorithm, like softmax regression, should be sufficient to achieve accurate recognition rates. The literature reviewed showed that this alternative approach has not been considered yet in the context of Arabic character recognition, which deserves to be investigated and evaluate its performance for such problem."}, {"link": "https://pdfs.semanticscholar.org/cf04/24ee5e4312a9d50ba0358e690f7825ce0418.pdf", "title": "Accelerated Asynchronous Greedy Coordinate Descent Algorithm for SVMs", "authors": [{"firstName": "B.", "middleNames": [], "lastName": "Gu"}, {"firstName": "Yingying", "middleNames": [], "lastName": "Shan"}, {"firstName": "Xiang", "middleNames": [], "lastName": "Geng"}, {"firstName": "Guansheng", "middleNames": [], "lastName": "Zheng"}], "abstract": "Support vector machines (SVMs) play an important role in machine learning in the last two decades. Traditional SVM solvers (e.g. LIBSVM) are not scalable in the current big data era. Recently, a state of the art solver was proposed based on the asynchronous greedy coordinate descent (AsyGCD) algorithm. However, AsyGCD is still not scalable enough, and is limited to binary classification. To address these issues, in this paper we propose an asynchronous accelerated greedy coordinate descent algorithm (AsyAGCD) for SVMs. Compared with AsyGCD, our AsyAGCD has the following two-fold advantages: 1) Our AsyAGCD is an accelerated version of AsyGCD because active set strategy is used. Specifically, our AsyAGCD can converge much faster than AsyGCD for the second half of iterations. 2) Our AsyAGCD can handle more SVM formulations (including binary classification and regression SVMs) than AsyGCD. We provide the comparison of computational complexity of AsyGCD and our AsyAGCD. Experiment results on a variety of datasets and learning applications confirm that our AsyAGCD is much faster than the existing SVM solvers (including AsyGCD).", "date": "2018-07-01"}, {"title": "A comprehensive and heuristic approach for Personalized Web Search using Greedy Algorithm", "authors": [], "abstract": "Personalized web search (PWS) used for developing the quality of various search services on the Internet. Users might experience failure when search engines return unrelated results that do not meet their real intentions. Such irrelevance is largely due to the huge variety of users\u2019 contexts and backgrounds, as well as the ambiguity of texts. However, evidences show that user\u2019s private information during search has become known to publicly due to proliferation of PWS. We proposed a PWS framework so-called UPS that can adaptively generalize profiles by queries while respecting user specified privacy requirements. This project presents two greedy algorithms, namely Greedy DP and Greedy IL, for runtime generalization. It also provides an online prediction mechanism for determining whether personalizing a query is beneficial. Rough set theory, which has been used victoriously in solving problems in pattern recognition, machine learning, and data mining, centers around the idea that a set of individual objects may be approximated via a lower and upper bound. In order to obtain the profits that rough sets can provide for data mining and related tasks, efficient computation of these approximations is vital. Compared with the classic Set theory, Rough Set is a mathematical approach to describe imprecision, vagueness, and ambiguity in data analysis, and it was"}]