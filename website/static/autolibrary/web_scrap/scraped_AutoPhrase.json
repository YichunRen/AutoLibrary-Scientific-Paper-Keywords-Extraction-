[{"link": "https://arxiv.org/pdf/2002.12543.pdf", "title": "Metamorphic Testing: A New Approach for Generating Next Test Cases", "authors": [{"firstName": "T.", "middleNames": [], "lastName": "Chen"}, {"firstName": "S.", "middleNames": [], "lastName": "Cheung"}, {"firstName": "S.", "middleNames": [], "lastName": "Yiu"}], "abstract": "In software testing, a set of test cases is constructed according to some predefined selection criteria. The software is then examined against these test cases. Three interesting observations have been made on the current artifacts of software testing. Firstly, an error-revealing test case is considered useful while a successful test case which does not reveal software errors is usually not further investigated. Whether these successful test cases still contain useful information for revealing software errors has not been properly studied. Secondly, no matter how extensive the testing has been conducted in the development phase, errors may still exist in the software [5]. These errors, if left undetected, may eventually cause damage to the production system. The study of techniques for uncovering software errors in the production phase is seldom addressed in the literature. Thirdly, as indicated by Weyuker in [6], the availability of test oracles is pragmatically unattainable in most situations. However, the availability of test oracles is generally assumed in conventional software testing techniques. In this paper, we propose a novel test case selection technique that derives new test cases from the successful ones. The selection aims at revealing software errors that are possibly left undetected in successful test cases which may be generated using some existing strategies. As such, the proposed technique augments the effectiveness of existing test selection strategies. The technique also helps uncover software errors in the production phase and can be used in the absence of test oracles.", "date": "2020-02-28"}, {"link": "https://doi.org/10.1287/isre.6.2.144", "title": "Understanding Information Technology Usage: A Test of Competing Models", "authors": [{"firstName": "S.", "middleNames": [], "lastName": "Taylor"}, {"firstName": "P.", "middleNames": [], "lastName": "Todd"}], "abstract": "The Technology Acceptance Model and two variations of the Theory of Planned Behavior were compared to assess which model best helps to understand usage of information technology. The models were compared using student data collected from 786 potential users of a computer resource center. Behavior data was based on monitoring 3,780 visits to the resource center over a 12-week period. Weighted least squares estimation revealed that all three models performed well in terms of fit and were roughly equivalent in terms of their ability to explain behavior. Decomposing the belief structures in the Theory of Planned Behavior provided a moderate increase in the explanation of behavioral intention. Overall, the results indicate that the decomposed Theory of Planned Behavior provides a fuller understanding of behavioral intention by focusing on the factors that are likely to influence systems use through the application of both design and implementation strategies.", "date": "1995-06-01"}, {"link": "https://pdfs.semanticscholar.org/391d/d4ca2ee3b2995260425d09dd97d4d9aaac29.pdf", "title": "Computer Self-Efficacy: Development of a Measure and Initial Test", "authors": [{"firstName": "Deborah", "middleNames": [], "lastName": "Compeau"}, {"firstName": "C.", "middleNames": [], "lastName": "Higgins"}], "abstract": "This paper discusses the role of individuals' beliefs about their abilities to competently use computers (computer self-efficacy) in the determination of computer use. A survey of Canadian managers and professionals was conducted to develop and validate a measure of computer self-efficacy and to assess both its impacts and antecedents. Computer self- efficacy was found to exert a significant influence on individuals' expectations of the outcomes of using computers, their emotional reactions to computers (affect and anxiety), as well as their actual computer use. An individual's self-efficacy and outcome expecta- tions were found to be positively influenced by the encouragement of others in their work group, as well as others' use of computers. Thus, self-efficacy represents an important individual trait, which moderates organizational influences (such as encouragement and support) on an individual's decision to use computers. Understanding self-efficacy, then, is important to the successful implementation of systems in organizations. The existence of a reliable and valid measure of self-efficacy makes assessment possible and should have implications for organizational support, training, and implementation.", "date": "1995-06-01"}, {"link": "https://pdfs.semanticscholar.org/c9b9/7d0794b5efe51e62ffc519c6a10d159c7a26.pdf", "title": "High Confidence Visual Recognition of Persons by a Test of Statistical Independence", "authors": [{"firstName": "J.", "middleNames": [], "lastName": "Daugman"}], "abstract": "A method for rapid visual recognition of personal identity is described, based on the failure of a statistical test of independence. The most unique phenotypic feature visible in a person's face is the detailed texture of each eye's iris. The visible texture of a person's iris in a real-time video image is encoded into a compact sequence of multi-scale quadrature 2-D Gabor wavelet coefficients, whose most-significant bits comprise a 256-byte \"iris code\". Statistical decision theory generates identification decisions from Exclusive-OR comparisons of complete iris codes at the rate of 4000 per second, including calculation of decision confidence levels. The distributions observed empirically in such comparisons imply a theoretical \"cross-over\" error rate of one in 131000 when a decision criterion is adopted that would equalize the false accept and false reject error rates. In the typical recognition case, given the mean observed degree of iris code agreement, the decision confidence levels correspond formally to a conditional false accept probability of one in about 10/sup 31/. >", "date": "1993-11-01"}, {"link": "http://dl.acm.org/citation.cfm?id=2188410", "title": "A Kernel Two-Sample Test", "authors": [{"firstName": "A.", "middleNames": [], "lastName": "Gretton"}, {"firstName": "K.", "middleNames": [], "lastName": "Borgwardt"}, {"firstName": "Malte", "middleNames": ["J."], "lastName": "Rasch"}, {"firstName": "B.", "middleNames": [], "lastName": "Sch\u00f6lkopf"}, {"firstName": "Alex", "middleNames": [], "lastName": "Smola"}], "abstract": "We propose a framework for analyzing and comparing distributions, which we use to construct statistical tests to determine if two samples are drawn from different distributions. Our test statistic is the largest difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS), and is called the maximum mean discrepancy (MMD).We present two distribution free tests based on large deviation bounds for the MMD, and a third test based on the asymptotic distribution of this statistic. The MMD can be computed in quadratic time, although efficient linear time approximations are available. Our statistic is an instance of an integral probability metric, and various classical metrics on distributions are obtained when alternative function classes are used in place of an RKHS. We apply our two-sample tests to a variety of problems, including attribute matching for databases using the Hungarian marriage method, where they perform strongly. Excellent performance is also obtained when comparing distributions over graphs, for which these are the first such tests.", "date": "2012-03-01"}]